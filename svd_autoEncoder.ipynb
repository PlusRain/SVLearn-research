{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bafd092-5879-4811-a1fd-86521948c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc75c14-aade-48cb-a5eb-2ac4a96c5539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training set has 50000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), transforms.ToTensor()])\n",
    "\n",
    "training_set = torchvision.datasets.CIFAR10('./data', train=True, \n",
    "                                            download=True,transform=transform)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=64, shuffle=True)\n",
    "\n",
    "validation_set = torchvision.datasets.CIFAR10('./data', train=False,\n",
    "                                            download=True,transform=transform)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b00391d-b185-43d6-b9fe-3d3c3f2fae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_labels(image_batch):\n",
    "    flatten_labels = []\n",
    "    for image in image_batch:\n",
    "        squeeze_image = image.squeeze()\n",
    "        label = np.reshape(squeeze_image, -1)\n",
    "        flatten_labels.append(label)\n",
    "    return torch.stack(flatten_labels)\n",
    "\n",
    "training_labels = [unsupervised_labels(batch[0]).to(device) for batch in training_loader]\n",
    "validation_labels = [unsupervised_labels(batch[0]).to(device) for batch in validation_loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d32a560-9a67-480b-8eb4-9b2e1e981802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12357c08-5f25-423b-a599-bb2add81f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_size=1024, hidden_layer_size=32):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.input_size = input_size\n",
    "        self.output_size = input_size\n",
    "        self.encoder = nn.Linear(self.input_size, self.hidden_layer_size)\n",
    "        self.decoder = nn.Linear(hidden_layer_size, self.output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # forward for encoder\n",
    "        x = self.encoder(x)\n",
    "        # forward for decoder\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "model = AutoEncoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed7b8d98-8888-42e5-953c-82bded7ffd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f39e2b04-bf8d-4a70-96f2-22d516aefe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    for i, (tdata, _) in enumerate(training_loader):\n",
    "        inputs = tdata.view(tdata.shape[0], -1).to(device)\n",
    "\n",
    "        labels = training_labels[i]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            last_loss = running_loss / 100\n",
    "            print(\"batch {} loss:{}\".format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e9c4028-0e9b-4325-9d1d-ac6b8580b9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nmse(outputs, labels):\n",
    "    mse = ((outputs - labels) ** 2).mean(axis=1)\n",
    "    norm = (labels ** 2).mean(axis=1)\n",
    "    nmse = mse / norm\n",
    "    return nmse\n",
    "\n",
    "def compute_mae(outputs, labels):\n",
    "    mae = torch.abs(outputs - labels).mean(axis=1)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b78495e-04e9-4654-a49a-df8af49af2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH1\n",
      "batch 100 loss:0.05631983008235693\n",
      "batch 200 loss:0.057157944776117804\n",
      "batch 300 loss:0.056434975638985634\n",
      "batch 400 loss:0.05648297540843487\n",
      "batch 500 loss:0.056494259461760524\n",
      "batch 600 loss:0.0559496109560132\n",
      "batch 700 loss:0.056919806599617005\n",
      "LOSS train 0.056919806599617005 valid 0.05638476833701134\n",
      "nmse: [0.13455139 0.4680297  0.23216903 ... 0.12032188 0.15642512 0.11324117]\n",
      "mae: tensor([0.1430, 0.1353, 0.1675, 0.1343, 0.2557, 0.2123, 0.3844, 0.2208, 0.2162,\n",
      "        0.2058, 0.2856, 0.1774, 0.2253, 0.2105, 0.1428, 0.1264],\n",
      "       device='cuda:0')\n",
      "EPOCH2\n",
      "batch 100 loss:0.05637755442410707\n",
      "batch 200 loss:0.057246743552386764\n",
      "batch 300 loss:0.05649072241038084\n",
      "batch 400 loss:0.05650378327816725\n",
      "batch 500 loss:0.05643672339618206\n",
      "batch 600 loss:0.05593788389116525\n",
      "batch 700 loss:0.05695688217878342\n",
      "LOSS train 0.05695688217878342 valid 0.05645148828625679\n",
      "nmse: [0.1386361  0.46713245 0.22896944 ... 0.12711667 0.14989707 0.11343268]\n",
      "mae: tensor([0.1389, 0.1350, 0.1670, 0.1333, 0.2592, 0.2117, 0.3899, 0.2225, 0.2166,\n",
      "        0.2015, 0.2883, 0.1781, 0.2234, 0.2165, 0.1397, 0.1257],\n",
      "       device='cuda:0')\n",
      "EPOCH3\n",
      "batch 100 loss:0.056384331434965136\n",
      "batch 200 loss:0.05722581725567579\n",
      "batch 300 loss:0.056465824358165266\n",
      "batch 400 loss:0.05650066047906876\n",
      "batch 500 loss:0.05645474404096604\n",
      "batch 600 loss:0.0559498742595315\n",
      "batch 700 loss:0.0569710598886013\n",
      "LOSS train 0.0569710598886013 valid 0.05631893500685692\n",
      "nmse: [0.13694091 0.4681925  0.2301526  ... 0.12133688 0.15098876 0.1148199 ]\n",
      "mae: tensor([0.1403, 0.1354, 0.1679, 0.1332, 0.2562, 0.2125, 0.3865, 0.2182, 0.2149,\n",
      "        0.2038, 0.2854, 0.1783, 0.2275, 0.2110, 0.1402, 0.1289],\n",
      "       device='cuda:0')\n",
      "EPOCH4\n",
      "batch 100 loss:0.056310747563838956\n",
      "batch 200 loss:0.0571795305237174\n",
      "batch 300 loss:0.05640156514942646\n",
      "batch 400 loss:0.05648366246372461\n",
      "batch 500 loss:0.056446385867893696\n",
      "batch 600 loss:0.055941743440926076\n",
      "batch 700 loss:0.05694373168051243\n",
      "LOSS train 0.05694373168051243 valid 0.05642222240567207\n",
      "nmse: [0.1347492  0.4659978  0.22937925 ... 0.12273601 0.14843512 0.11203984]\n",
      "mae: tensor([0.1390, 0.1328, 0.1662, 0.1341, 0.2567, 0.2107, 0.3863, 0.2201, 0.2169,\n",
      "        0.2039, 0.2865, 0.1785, 0.2257, 0.2121, 0.1392, 0.1262],\n",
      "       device='cuda:0')\n",
      "EPOCH5\n",
      "batch 100 loss:0.05627215877175331\n",
      "batch 200 loss:0.05718194007873535\n",
      "batch 300 loss:0.05644706316292286\n",
      "batch 400 loss:0.05650436151772738\n",
      "batch 500 loss:0.05648959308862686\n",
      "batch 600 loss:0.05595909733325243\n",
      "batch 700 loss:0.05692961536347866\n",
      "LOSS train 0.05692961536347866 valid 0.05630790442228317\n",
      "nmse: [0.13685796 0.47198436 0.2311146  ... 0.12141968 0.15247883 0.11394597]\n",
      "mae: tensor([0.1400, 0.1360, 0.1672, 0.1343, 0.2564, 0.2127, 0.3859, 0.2215, 0.2173,\n",
      "        0.2043, 0.2860, 0.1766, 0.2247, 0.2113, 0.1405, 0.1269],\n",
      "       device='cuda:0')\n",
      "EPOCH6\n",
      "batch 100 loss:0.056318125165998933\n",
      "batch 200 loss:0.05718004859983921\n",
      "batch 300 loss:0.05641653124243021\n",
      "batch 400 loss:0.05650876581668854\n",
      "batch 500 loss:0.05648808013647795\n",
      "batch 600 loss:0.0559683633223176\n",
      "batch 700 loss:0.05693358022719622\n",
      "LOSS train 0.05693358022719622 valid 0.05632661655545235\n",
      "nmse: [0.13304575 0.47076514 0.22797759 ... 0.12087142 0.15409797 0.11298312]\n",
      "mae: tensor([0.1390, 0.1356, 0.1684, 0.1327, 0.2568, 0.2126, 0.3852, 0.2169, 0.2145,\n",
      "        0.2050, 0.2852, 0.1765, 0.2245, 0.2108, 0.1413, 0.1257],\n",
      "       device='cuda:0')\n",
      "EPOCH7\n",
      "batch 100 loss:0.056291661448776724\n",
      "batch 200 loss:0.057168205380439756\n",
      "batch 300 loss:0.05643118742853403\n",
      "batch 400 loss:0.056502267345786096\n",
      "batch 500 loss:0.05645509265363216\n",
      "batch 600 loss:0.05596788767725229\n",
      "batch 700 loss:0.05693095155060291\n",
      "LOSS train 0.05693095155060291 valid 0.056376561522483826\n",
      "nmse: [0.13706093 0.4614929  0.22587712 ... 0.12350005 0.15122637 0.11350718]\n",
      "mae: tensor([0.1394, 0.1362, 0.1687, 0.1337, 0.2583, 0.2109, 0.3883, 0.2204, 0.2155,\n",
      "        0.1994, 0.2879, 0.1776, 0.2231, 0.2130, 0.1403, 0.1265],\n",
      "       device='cuda:0')\n",
      "EPOCH8\n",
      "batch 100 loss:0.056361584514379504\n",
      "batch 200 loss:0.05721840124577284\n",
      "batch 300 loss:0.056464797742664816\n",
      "batch 400 loss:0.05649202704429626\n",
      "batch 500 loss:0.0564598374068737\n",
      "batch 600 loss:0.05594914220273495\n",
      "batch 700 loss:0.05706049390137195\n",
      "LOSS train 0.05706049390137195 valid 0.0563819445669651\n",
      "nmse: [0.13675626 0.466698   0.2244562  ... 0.12044097 0.15613763 0.11579666]\n",
      "mae: tensor([0.1416, 0.1345, 0.1624, 0.1374, 0.2528, 0.2113, 0.3829, 0.2222, 0.2186,\n",
      "        0.2053, 0.2856, 0.1775, 0.2234, 0.2112, 0.1427, 0.1280],\n",
      "       device='cuda:0')\n",
      "EPOCH9\n",
      "batch 100 loss:0.05633315850049257\n",
      "batch 200 loss:0.05724204361438751\n",
      "batch 300 loss:0.05641369495540857\n",
      "batch 400 loss:0.05649235561490059\n",
      "batch 500 loss:0.056467022486031054\n",
      "batch 600 loss:0.05593473792076111\n",
      "batch 700 loss:0.056939075365662575\n",
      "LOSS train 0.056939075365662575 valid 0.056319840252399445\n",
      "nmse: [0.13391805 0.4697832  0.22799356 ... 0.11791288 0.15549332 0.11472791]\n",
      "mae: tensor([0.1415, 0.1350, 0.1667, 0.1367, 0.2536, 0.2147, 0.3836, 0.2216, 0.2172,\n",
      "        0.2045, 0.2848, 0.1775, 0.2254, 0.2080, 0.1426, 0.1271],\n",
      "       device='cuda:0')\n",
      "EPOCH10\n",
      "batch 100 loss:0.0562783582136035\n",
      "batch 200 loss:0.05716612663120031\n",
      "batch 300 loss:0.05644611559808254\n",
      "batch 400 loss:0.056492625661194326\n",
      "batch 500 loss:0.05645724378526211\n",
      "batch 600 loss:0.055969252809882165\n",
      "batch 700 loss:0.05694951593875885\n",
      "LOSS train 0.05694951593875885 valid 0.05629301443696022\n",
      "nmse: [0.13512094 0.47091207 0.2274087  ... 0.1178449  0.15516023 0.11380067]\n",
      "mae: tensor([0.1411, 0.1379, 0.1688, 0.1345, 0.2542, 0.2145, 0.3831, 0.2199, 0.2181,\n",
      "        0.2064, 0.2862, 0.1766, 0.2267, 0.2081, 0.1421, 0.1261],\n",
      "       device='cuda:0')\n",
      "EPOCH11\n",
      "batch 100 loss:0.056360165476799014\n",
      "batch 200 loss:0.0572100418061018\n",
      "batch 300 loss:0.05644637428224087\n",
      "batch 400 loss:0.056523243375122545\n",
      "batch 500 loss:0.05646011214703321\n",
      "batch 600 loss:0.0559603825211525\n",
      "batch 700 loss:0.05692166760563851\n",
      "LOSS train 0.05692166760563851 valid 0.056397780776023865\n",
      "nmse: [0.1336976  0.47034    0.22894506 ... 0.12230061 0.14966984 0.11292536]\n",
      "mae: tensor([0.1394, 0.1332, 0.1678, 0.1348, 0.2568, 0.2122, 0.3860, 0.2208, 0.2148,\n",
      "        0.2042, 0.2874, 0.1789, 0.2265, 0.2124, 0.1396, 0.1258],\n",
      "       device='cuda:0')\n",
      "EPOCH12\n",
      "batch 100 loss:0.056333845518529414\n",
      "batch 200 loss:0.057195020690560344\n",
      "batch 300 loss:0.05643299646675587\n",
      "batch 400 loss:0.05649164017289877\n",
      "batch 500 loss:0.056467615105211734\n",
      "batch 600 loss:0.05596457224339247\n",
      "batch 700 loss:0.05698671694844961\n",
      "LOSS train 0.05698671694844961 valid 0.056392937898635864\n",
      "nmse: [0.13567059 0.46959177 0.22866808 ... 0.12397721 0.14830402 0.10840556]\n",
      "mae: tensor([0.1387, 0.1372, 0.1679, 0.1326, 0.2599, 0.2109, 0.3890, 0.2185, 0.2149,\n",
      "        0.2016, 0.2899, 0.1802, 0.2202, 0.2135, 0.1390, 0.1222],\n",
      "       device='cuda:0')\n",
      "EPOCH13\n",
      "batch 100 loss:0.05634772647172213\n",
      "batch 200 loss:0.05724167302250862\n",
      "batch 300 loss:0.056453346386551854\n",
      "batch 400 loss:0.056503044925630096\n",
      "batch 500 loss:0.05644221652299166\n",
      "batch 600 loss:0.05599965997040272\n",
      "batch 700 loss:0.05700604621320963\n",
      "LOSS train 0.05700604621320963 valid 0.056409094482660294\n",
      "nmse: [0.1364472  0.46391279 0.22728077 ... 0.12096186 0.15355945 0.11421673]\n",
      "mae: tensor([0.1403, 0.1334, 0.1646, 0.1355, 0.2554, 0.2108, 0.3850, 0.2198, 0.2164,\n",
      "        0.2063, 0.2877, 0.1778, 0.2271, 0.2107, 0.1414, 0.1267],\n",
      "       device='cuda:0')\n",
      "EPOCH14\n",
      "batch 100 loss:0.056300861686468126\n",
      "batch 200 loss:0.05718973197042942\n",
      "batch 300 loss:0.056407684460282326\n",
      "batch 400 loss:0.05648766931146383\n",
      "batch 500 loss:0.056458948887884615\n",
      "batch 600 loss:0.05593813937157392\n",
      "batch 700 loss:0.056963611990213395\n",
      "LOSS train 0.056963611990213395 valid 0.05639766529202461\n",
      "nmse: [0.13686495 0.46785983 0.22464736 ... 0.12203913 0.15233593 0.11490881]\n",
      "mae: tensor([0.1419, 0.1347, 0.1646, 0.1335, 0.2559, 0.2133, 0.3843, 0.2238, 0.2160,\n",
      "        0.2032, 0.2869, 0.1773, 0.2251, 0.2121, 0.1403, 0.1281],\n",
      "       device='cuda:0')\n",
      "EPOCH15\n",
      "batch 100 loss:0.05631689559668303\n",
      "batch 200 loss:0.05720117412507534\n",
      "batch 300 loss:0.05645296335220337\n",
      "batch 400 loss:0.056491599902510646\n",
      "batch 500 loss:0.056477614790201185\n",
      "batch 600 loss:0.055982487984001635\n",
      "batch 700 loss:0.05696712277829647\n",
      "LOSS train 0.05696712277829647 valid 0.056361738592386246\n",
      "nmse: [0.13604893 0.47211203 0.22899744 ... 0.12290745 0.15197253 0.1135764 ]\n",
      "mae: tensor([0.1394, 0.1359, 0.1671, 0.1318, 0.2586, 0.2117, 0.3870, 0.2211, 0.2154,\n",
      "        0.2039, 0.2929, 0.1769, 0.2218, 0.2126, 0.1406, 0.1260],\n",
      "       device='cuda:0')\n",
      "EPOCH16\n",
      "batch 100 loss:0.05629325844347477\n",
      "batch 200 loss:0.05719500448554754\n",
      "batch 300 loss:0.05641823034733534\n",
      "batch 400 loss:0.056494038216769696\n",
      "batch 500 loss:0.05644897308200598\n",
      "batch 600 loss:0.05594961754977703\n",
      "batch 700 loss:0.05695759166032076\n",
      "LOSS train 0.05695759166032076 valid 0.056349240243434906\n",
      "nmse: [0.13620707 0.46946907 0.22813432 ... 0.11907607 0.15332462 0.11413807]\n",
      "mae: tensor([0.1402, 0.1355, 0.1664, 0.1354, 0.2550, 0.2120, 0.3851, 0.2191, 0.2170,\n",
      "        0.2052, 0.2865, 0.1769, 0.2250, 0.2095, 0.1413, 0.1268],\n",
      "       device='cuda:0')\n",
      "EPOCH17\n",
      "batch 100 loss:0.05629726320505142\n",
      "batch 200 loss:0.05720437694340944\n",
      "batch 300 loss:0.05643909201025963\n",
      "batch 400 loss:0.056490841470658776\n",
      "batch 500 loss:0.05648360546678305\n",
      "batch 600 loss:0.05596595726907253\n",
      "batch 700 loss:0.0569419152289629\n",
      "LOSS train 0.0569419152289629 valid 0.05633864551782608\n",
      "nmse: [0.13587557 0.46894297 0.2261998  ... 0.11925092 0.15391706 0.11490254]\n",
      "mae: tensor([0.1399, 0.1345, 0.1664, 0.1358, 0.2562, 0.2143, 0.3848, 0.2171, 0.2168,\n",
      "        0.2051, 0.2829, 0.1777, 0.2245, 0.2093, 0.1416, 0.1273],\n",
      "       device='cuda:0')\n",
      "EPOCH18\n",
      "batch 100 loss:0.05632424868643284\n",
      "batch 200 loss:0.0571783359721303\n",
      "batch 300 loss:0.056473768465220925\n",
      "batch 400 loss:0.05650180488824844\n",
      "batch 500 loss:0.05644788842648268\n",
      "batch 600 loss:0.05596937108784914\n",
      "batch 700 loss:0.05691755354404449\n",
      "LOSS train 0.05691755354404449 valid 0.05639692768454552\n",
      "nmse: [0.13627355 0.46625486 0.23076652 ... 0.12298055 0.15184997 0.11399996]\n",
      "mae: tensor([0.1396, 0.1348, 0.1665, 0.1346, 0.2558, 0.2112, 0.3860, 0.2226, 0.2175,\n",
      "        0.2029, 0.2855, 0.1767, 0.2261, 0.2128, 0.1403, 0.1262],\n",
      "       device='cuda:0')\n",
      "EPOCH19\n",
      "batch 100 loss:0.056330591402947904\n",
      "batch 200 loss:0.05722590282559395\n",
      "batch 300 loss:0.05641947939991951\n",
      "batch 400 loss:0.05650411959737539\n",
      "batch 500 loss:0.0564537550136447\n",
      "batch 600 loss:0.05596467345952988\n",
      "batch 700 loss:0.057001745812594894\n",
      "LOSS train 0.057001745812594894 valid 0.05633408948779106\n",
      "nmse: [0.1342422  0.46695164 0.22929685 ... 0.12025499 0.15190414 0.11277205]\n",
      "mae: tensor([0.1398, 0.1345, 0.1677, 0.1336, 0.2562, 0.2138, 0.3857, 0.2184, 0.2144,\n",
      "        0.2034, 0.2873, 0.1764, 0.2244, 0.2110, 0.1405, 0.1254],\n",
      "       device='cuda:0')\n",
      "EPOCH20\n",
      "batch 100 loss:0.05630043562501669\n",
      "batch 200 loss:0.05719745263457298\n",
      "batch 300 loss:0.05645272701978683\n",
      "batch 400 loss:0.05650667551904917\n",
      "batch 500 loss:0.05644708331674338\n",
      "batch 600 loss:0.055963059328496455\n",
      "batch 700 loss:0.056969664506614205\n",
      "LOSS train 0.056969664506614205 valid 0.05636296048760414\n",
      "nmse: [0.13935924 0.46919355 0.22811933 ... 0.12148174 0.15294255 0.11457269]\n",
      "mae: tensor([0.1398, 0.1360, 0.1665, 0.1349, 0.2553, 0.2115, 0.3854, 0.2202, 0.2174,\n",
      "        0.2048, 0.2869, 0.1761, 0.2249, 0.2114, 0.1414, 0.1266],\n",
      "       device='cuda:0')\n",
      "EPOCH21\n",
      "batch 100 loss:0.056349097676575186\n",
      "batch 200 loss:0.05723344124853611\n",
      "batch 300 loss:0.05642967414110899\n",
      "batch 400 loss:0.056501328200101855\n",
      "batch 500 loss:0.05645381361246109\n",
      "batch 600 loss:0.055977536775171755\n",
      "batch 700 loss:0.0569420351088047\n",
      "LOSS train 0.0569420351088047 valid 0.056385722011327744\n",
      "nmse: [0.13876237 0.4690201  0.22588962 ... 0.12314551 0.15151213 0.11481953]\n",
      "mae: tensor([0.1388, 0.1337, 0.1630, 0.1362, 0.2540, 0.2133, 0.3854, 0.2209, 0.2162,\n",
      "        0.2027, 0.2861, 0.1774, 0.2227, 0.2134, 0.1402, 0.1267],\n",
      "       device='cuda:0')\n",
      "EPOCH22\n",
      "batch 100 loss:0.05628179039806128\n",
      "batch 200 loss:0.057147705480456355\n",
      "batch 300 loss:0.05640171986073256\n",
      "batch 400 loss:0.056481907665729525\n",
      "batch 500 loss:0.056466597318649295\n",
      "batch 600 loss:0.05597365073859692\n",
      "batch 700 loss:0.05698494791984558\n",
      "LOSS train 0.05698494791984558 valid 0.056356754153966904\n",
      "nmse: [0.1368204  0.46337405 0.22786966 ... 0.12173322 0.15129325 0.11284171]\n",
      "mae: tensor([0.1387, 0.1377, 0.1668, 0.1337, 0.2597, 0.2137, 0.3871, 0.2201, 0.2156,\n",
      "        0.2023, 0.2885, 0.1785, 0.2231, 0.2118, 0.1404, 0.1253],\n",
      "       device='cuda:0')\n",
      "EPOCH23\n",
      "batch 100 loss:0.056312988474965096\n",
      "batch 200 loss:0.0572352322563529\n",
      "batch 300 loss:0.05643136534839868\n",
      "batch 400 loss:0.05650073647499085\n",
      "batch 500 loss:0.05645705360919237\n",
      "batch 600 loss:0.05593525309115648\n",
      "batch 700 loss:0.05693957976996899\n",
      "LOSS train 0.05693957976996899 valid 0.05631788447499275\n",
      "nmse: [0.1345754  0.47009647 0.22633028 ... 0.12029981 0.1519328  0.11256227]\n",
      "mae: tensor([0.1402, 0.1365, 0.1693, 0.1334, 0.2547, 0.2135, 0.3852, 0.2187, 0.2168,\n",
      "        0.2043, 0.2876, 0.1766, 0.2240, 0.2107, 0.1405, 0.1257],\n",
      "       device='cuda:0')\n",
      "EPOCH24\n",
      "batch 100 loss:0.056272603534162045\n",
      "batch 200 loss:0.057193746119737626\n",
      "batch 300 loss:0.0564222015067935\n",
      "batch 400 loss:0.05649731833487749\n",
      "batch 500 loss:0.056447987332940104\n",
      "batch 600 loss:0.055925622731447217\n",
      "batch 700 loss:0.05692143015563488\n",
      "LOSS train 0.05692143015563488 valid 0.056362688541412354\n",
      "nmse: [0.13634591 0.4673248  0.23010473 ... 0.1235328  0.1529006  0.11506484]\n",
      "mae: tensor([0.1398, 0.1356, 0.1658, 0.1348, 0.2571, 0.2124, 0.3851, 0.2220, 0.2169,\n",
      "        0.2020, 0.2861, 0.1764, 0.2234, 0.2135, 0.1409, 0.1282],\n",
      "       device='cuda:0')\n",
      "EPOCH25\n",
      "batch 100 loss:0.05630621001124382\n",
      "batch 200 loss:0.05720345679670572\n",
      "batch 300 loss:0.05642071329057217\n",
      "batch 400 loss:0.05649315368384123\n",
      "batch 500 loss:0.05645165134221315\n",
      "batch 600 loss:0.055964113734662535\n",
      "batch 700 loss:0.05696451213210821\n",
      "LOSS train 0.05696451213210821 valid 0.05638895183801651\n",
      "nmse: [0.13704209 0.46918574 0.23178568 ... 0.11902124 0.15917166 0.11525108]\n",
      "mae: tensor([0.1417, 0.1349, 0.1657, 0.1362, 0.2537, 0.2112, 0.3841, 0.2202, 0.2159,\n",
      "        0.2043, 0.2854, 0.1777, 0.2249, 0.2092, 0.1442, 0.1277],\n",
      "       device='cuda:0')\n",
      "EPOCH26\n",
      "batch 100 loss:0.05634064082056284\n",
      "batch 200 loss:0.05724124412983656\n",
      "batch 300 loss:0.05643892206251621\n",
      "batch 400 loss:0.05648578442633152\n",
      "batch 500 loss:0.056489178203046324\n",
      "batch 600 loss:0.05599671885371208\n",
      "batch 700 loss:0.05693694606423378\n",
      "LOSS train 0.05693694606423378 valid 0.05640735104680061\n",
      "nmse: [0.13538496 0.46336383 0.23053673 ... 0.12331414 0.15051489 0.11319704]\n",
      "mae: tensor([0.1387, 0.1348, 0.1673, 0.1330, 0.2578, 0.2118, 0.3887, 0.2211, 0.2154,\n",
      "        0.2040, 0.2894, 0.1778, 0.2224, 0.2128, 0.1396, 0.1264],\n",
      "       device='cuda:0')\n",
      "EPOCH27\n",
      "batch 100 loss:0.05630648203194141\n",
      "batch 200 loss:0.057183799222111704\n",
      "batch 300 loss:0.05642076283693313\n",
      "batch 400 loss:0.0564775725454092\n",
      "batch 500 loss:0.05648873310536146\n",
      "batch 600 loss:0.05599257916212082\n",
      "batch 700 loss:0.05693941358476877\n",
      "LOSS train 0.05693941358476877 valid 0.05639094486832619\n",
      "nmse: [0.13806051 0.46523598 0.22939582 ... 0.11995633 0.15540259 0.113065  ]\n",
      "mae: tensor([0.1412, 0.1363, 0.1633, 0.1348, 0.2556, 0.2124, 0.3852, 0.2197, 0.2162,\n",
      "        0.2054, 0.2861, 0.1779, 0.2270, 0.2097, 0.1423, 0.1265],\n",
      "       device='cuda:0')\n",
      "EPOCH28\n",
      "batch 100 loss:0.05633954416960478\n",
      "batch 200 loss:0.05721886940300465\n",
      "batch 300 loss:0.05644941978156567\n",
      "batch 400 loss:0.056528694555163385\n",
      "batch 500 loss:0.056453012451529505\n",
      "batch 600 loss:0.0559702055901289\n",
      "batch 700 loss:0.0569594220072031\n",
      "LOSS train 0.0569594220072031 valid 0.05635535717010498\n",
      "nmse: [0.13383964 0.4697912  0.23375541 ... 0.12200277 0.14940721 0.11259414]\n",
      "mae: tensor([0.1384, 0.1348, 0.1635, 0.1332, 0.2573, 0.2120, 0.3857, 0.2209, 0.2150,\n",
      "        0.2025, 0.2871, 0.1762, 0.2242, 0.2121, 0.1396, 0.1257],\n",
      "       device='cuda:0')\n",
      "EPOCH29\n",
      "batch 100 loss:0.056323941685259345\n",
      "batch 200 loss:0.05714917056262493\n",
      "batch 300 loss:0.05643417753279209\n",
      "batch 400 loss:0.05649061612784863\n",
      "batch 500 loss:0.056461275368928907\n",
      "batch 600 loss:0.05595866929739714\n",
      "batch 700 loss:0.056989919655025006\n",
      "LOSS train 0.056989919655025006 valid 0.056339215487241745\n",
      "nmse: [0.13700405 0.47618112 0.22754782 ... 0.12154204 0.15359622 0.11265764]\n",
      "mae: tensor([0.1397, 0.1362, 0.1671, 0.1333, 0.2586, 0.2137, 0.3854, 0.2197, 0.2156,\n",
      "        0.2045, 0.2839, 0.1766, 0.2230, 0.2115, 0.1412, 0.1256],\n",
      "       device='cuda:0')\n",
      "EPOCH30\n",
      "batch 100 loss:0.056316268853843214\n",
      "batch 200 loss:0.057189657017588616\n",
      "batch 300 loss:0.05641957212239504\n",
      "batch 400 loss:0.056484956368803976\n",
      "batch 500 loss:0.05644998289644718\n",
      "batch 600 loss:0.05601871196180582\n",
      "batch 700 loss:0.05693238962441683\n",
      "LOSS train 0.05693238962441683 valid 0.05642205849289894\n",
      "nmse: [0.13679707 0.4609829  0.22685389 ... 0.12695248 0.15319704 0.115435  ]\n",
      "mae: tensor([0.1388, 0.1354, 0.1650, 0.1329, 0.2587, 0.2116, 0.3870, 0.2192, 0.2161,\n",
      "        0.2050, 0.2886, 0.1784, 0.2239, 0.2160, 0.1407, 0.1276],\n",
      "       device='cuda:0')\n",
      "EPOCH31\n",
      "batch 100 loss:0.056302259787917135\n",
      "batch 200 loss:0.057184003554284574\n",
      "batch 300 loss:0.05647336911410093\n",
      "batch 400 loss:0.05647606909275055\n",
      "batch 500 loss:0.05645782068371773\n",
      "batch 600 loss:0.05594352409243584\n",
      "batch 700 loss:0.05689587153494358\n",
      "LOSS train 0.05689587153494358 valid 0.056346505880355835\n",
      "nmse: [0.13366148 0.4675557  0.22760847 ... 0.11974884 0.15379116 0.1126416 ]\n",
      "mae: tensor([0.1400, 0.1356, 0.1664, 0.1337, 0.2556, 0.2124, 0.3842, 0.2192, 0.2147,\n",
      "        0.2038, 0.2863, 0.1775, 0.2246, 0.2096, 0.1415, 0.1260],\n",
      "       device='cuda:0')\n",
      "EPOCH32\n",
      "batch 100 loss:0.056288476213812826\n",
      "batch 200 loss:0.05718647707253695\n",
      "batch 300 loss:0.056447544246912\n",
      "batch 400 loss:0.056474048644304276\n",
      "batch 500 loss:0.056468346565961836\n",
      "batch 600 loss:0.05598189763724804\n",
      "batch 700 loss:0.05698925439268351\n",
      "LOSS train 0.05698925439268351 valid 0.05637152120471001\n",
      "nmse: [0.13312456 0.4643884  0.22729185 ... 0.12226401 0.1535326  0.11338561]\n",
      "mae: tensor([0.1389, 0.1341, 0.1667, 0.1322, 0.2572, 0.2117, 0.3857, 0.2211, 0.2166,\n",
      "        0.2036, 0.2880, 0.1783, 0.2245, 0.2120, 0.1410, 0.1256],\n",
      "       device='cuda:0')\n",
      "EPOCH33\n",
      "batch 100 loss:0.056320446468889715\n",
      "batch 200 loss:0.057208199314773084\n",
      "batch 300 loss:0.056440765820443634\n",
      "batch 400 loss:0.05647615373134613\n",
      "batch 500 loss:0.05647821210324764\n",
      "batch 600 loss:0.05597211871296168\n",
      "batch 700 loss:0.05693006712943315\n",
      "LOSS train 0.05693006712943315 valid 0.056310612708330154\n",
      "nmse: [0.1370535  0.47043222 0.22584055 ... 0.12212022 0.1546852  0.11472069]\n",
      "mae: tensor([0.1401, 0.1356, 0.1675, 0.1340, 0.2566, 0.2115, 0.3855, 0.2216, 0.2161,\n",
      "        0.2038, 0.2870, 0.1780, 0.2242, 0.2124, 0.1420, 0.1271],\n",
      "       device='cuda:0')\n",
      "EPOCH34\n",
      "batch 100 loss:0.05632027935236692\n",
      "batch 200 loss:0.05722653932869434\n",
      "batch 300 loss:0.05644429221749306\n",
      "batch 400 loss:0.05649640545248985\n",
      "batch 500 loss:0.05646856416016817\n",
      "batch 600 loss:0.055996318608522416\n",
      "batch 700 loss:0.05698963087052107\n",
      "LOSS train 0.05698963087052107 valid 0.05640158802270889\n",
      "nmse: [0.13618474 0.4681702  0.22825089 ... 0.12167825 0.1556052  0.11732469]\n",
      "mae: tensor([0.1401, 0.1337, 0.1675, 0.1342, 0.2553, 0.2110, 0.3845, 0.2193, 0.2165,\n",
      "        0.2020, 0.2864, 0.1794, 0.2231, 0.2115, 0.1421, 0.1288],\n",
      "       device='cuda:0')\n",
      "EPOCH35\n",
      "batch 100 loss:0.056339309439063075\n",
      "batch 200 loss:0.05720407035201788\n",
      "batch 300 loss:0.056443297676742075\n",
      "batch 400 loss:0.056484504416584966\n",
      "batch 500 loss:0.056450278982520107\n",
      "batch 600 loss:0.055925961062312124\n",
      "batch 700 loss:0.05698605567216873\n",
      "LOSS train 0.05698605567216873 valid 0.05635535717010498\n",
      "nmse: [0.13535385 0.4638436  0.22600837 ... 0.1234251  0.15085945 0.11242474]\n",
      "mae: tensor([0.1409, 0.1354, 0.1673, 0.1353, 0.2558, 0.2130, 0.3861, 0.2202, 0.2156,\n",
      "        0.2052, 0.2873, 0.1781, 0.2232, 0.2131, 0.1404, 0.1251],\n",
      "       device='cuda:0')\n",
      "EPOCH36\n",
      "batch 100 loss:0.05635387841612101\n",
      "batch 200 loss:0.05717928621917963\n",
      "batch 300 loss:0.056452257819473745\n",
      "batch 400 loss:0.05648221042007208\n",
      "batch 500 loss:0.056447969563305375\n",
      "batch 600 loss:0.0559662813693285\n",
      "batch 700 loss:0.056971406303346156\n",
      "LOSS train 0.056971406303346156 valid 0.05635534226894379\n",
      "nmse: [0.13283013 0.47161272 0.23026457 ... 0.11821679 0.15170765 0.1119637 ]\n",
      "mae: tensor([0.1410, 0.1353, 0.1672, 0.1333, 0.2552, 0.2135, 0.3838, 0.2198, 0.2158,\n",
      "        0.2055, 0.2873, 0.1768, 0.2266, 0.2088, 0.1400, 0.1246],\n",
      "       device='cuda:0')\n",
      "EPOCH37\n",
      "batch 100 loss:0.05633144836872816\n",
      "batch 200 loss:0.05718116249889135\n",
      "batch 300 loss:0.056451510302722455\n",
      "batch 400 loss:0.05648891467601061\n",
      "batch 500 loss:0.05645945306867361\n",
      "batch 600 loss:0.05592224031686783\n",
      "batch 700 loss:0.05696267735213041\n",
      "LOSS train 0.05696267735213041 valid 0.056380607187747955\n",
      "nmse: [0.13250187 0.47579092 0.22804552 ... 0.11838395 0.15298596 0.11039882]\n",
      "mae: tensor([0.1402, 0.1337, 0.1660, 0.1337, 0.2551, 0.2121, 0.3846, 0.2205, 0.2167,\n",
      "        0.2044, 0.2855, 0.1765, 0.2254, 0.2092, 0.1414, 0.1251],\n",
      "       device='cuda:0')\n",
      "EPOCH38\n",
      "batch 100 loss:0.0563434537500143\n",
      "batch 200 loss:0.05719584118574858\n",
      "batch 300 loss:0.056446764506399634\n",
      "batch 400 loss:0.056500612646341326\n",
      "batch 500 loss:0.056490409187972546\n",
      "batch 600 loss:0.05600555054843426\n",
      "batch 700 loss:0.05692041754722595\n",
      "LOSS train 0.05692041754722595 valid 0.05627840757369995\n",
      "nmse: [0.1348548  0.47080255 0.2262046  ... 0.11910053 0.15405893 0.11331314]\n",
      "mae: tensor([0.1404, 0.1372, 0.1691, 0.1349, 0.2568, 0.2139, 0.3829, 0.2175, 0.2176,\n",
      "        0.2065, 0.2853, 0.1768, 0.2250, 0.2092, 0.1414, 0.1251],\n",
      "       device='cuda:0')\n",
      "EPOCH39\n",
      "batch 100 loss:0.056315376870334145\n",
      "batch 200 loss:0.05719995837658644\n",
      "batch 300 loss:0.05643735609948635\n",
      "batch 400 loss:0.056507349386811255\n",
      "batch 500 loss:0.05646054923534393\n",
      "batch 600 loss:0.055956777594983576\n",
      "batch 700 loss:0.056914756409823894\n",
      "LOSS train 0.056914756409823894 valid 0.05639679357409477\n",
      "nmse: [0.13448837 0.4673872  0.23160435 ... 0.11795357 0.15487643 0.11649152]\n",
      "mae: tensor([0.1419, 0.1341, 0.1655, 0.1359, 0.2526, 0.2132, 0.3815, 0.2210, 0.2173,\n",
      "        0.2067, 0.2823, 0.1761, 0.2267, 0.2084, 0.1419, 0.1296],\n",
      "       device='cuda:0')\n",
      "EPOCH40\n",
      "batch 100 loss:0.056308105513453485\n",
      "batch 200 loss:0.05715495314449072\n",
      "batch 300 loss:0.05642951227724552\n",
      "batch 400 loss:0.056499276831746104\n",
      "batch 500 loss:0.056462612189352515\n",
      "batch 600 loss:0.055916706174612044\n",
      "batch 700 loss:0.056947135403752326\n",
      "LOSS train 0.056947135403752326 valid 0.056484151631593704\n",
      "nmse: [0.13570301 0.46402127 0.22798795 ... 0.12183106 0.14977151 0.11809469]\n",
      "mae: tensor([0.1386, 0.1362, 0.1661, 0.1358, 0.2559, 0.2070, 0.3860, 0.2243, 0.2150,\n",
      "        0.2005, 0.2861, 0.1790, 0.2232, 0.2117, 0.1396, 0.1301],\n",
      "       device='cuda:0')\n",
      "EPOCH41\n",
      "batch 100 loss:0.05634679939597845\n",
      "batch 200 loss:0.057204589731991294\n",
      "batch 300 loss:0.05642508190125227\n",
      "batch 400 loss:0.05650416031479835\n",
      "batch 500 loss:0.05645756714046001\n",
      "batch 600 loss:0.0559527837485075\n",
      "batch 700 loss:0.056989218816161154\n",
      "LOSS train 0.056989218816161154 valid 0.056416019797325134\n",
      "nmse: [0.13819842 0.45662856 0.22741121 ... 0.12125403 0.15863003 0.11935035]\n",
      "mae: tensor([0.1404, 0.1348, 0.1643, 0.1369, 0.2582, 0.2099, 0.3849, 0.2189, 0.2165,\n",
      "        0.2051, 0.2866, 0.1794, 0.2206, 0.2108, 0.1433, 0.1294],\n",
      "       device='cuda:0')\n",
      "EPOCH42\n",
      "batch 100 loss:0.056321742758154866\n",
      "batch 200 loss:0.05721739154309034\n",
      "batch 300 loss:0.056425251550972465\n",
      "batch 400 loss:0.05648230500519276\n",
      "batch 500 loss:0.0564603578299284\n",
      "batch 600 loss:0.05593310568481684\n",
      "batch 700 loss:0.05689014136791229\n",
      "LOSS train 0.05689014136791229 valid 0.05633223056793213\n",
      "nmse: [0.13733673 0.4730843  0.22694236 ... 0.12186941 0.15128398 0.11342094]\n",
      "mae: tensor([0.1403, 0.1352, 0.1672, 0.1343, 0.2569, 0.2126, 0.3832, 0.2204, 0.2159,\n",
      "        0.2045, 0.2881, 0.1743, 0.2259, 0.2123, 0.1401, 0.1266],\n",
      "       device='cuda:0')\n",
      "EPOCH43\n",
      "batch 100 loss:0.05632078889757395\n",
      "batch 200 loss:0.05717373039573431\n",
      "batch 300 loss:0.05643407542258501\n",
      "batch 400 loss:0.05649095866829157\n",
      "batch 500 loss:0.05645880524069071\n",
      "batch 600 loss:0.05595305744558573\n",
      "batch 700 loss:0.056959991529583934\n",
      "LOSS train 0.056959991529583934 valid 0.056391406804323196\n",
      "nmse: [0.1352493  0.4663342  0.22714779 ... 0.12213374 0.15266456 0.11415385]\n",
      "mae: tensor([0.1379, 0.1362, 0.1660, 0.1334, 0.2584, 0.2109, 0.3873, 0.2220, 0.2159,\n",
      "        0.2030, 0.2885, 0.1787, 0.2236, 0.2121, 0.1410, 0.1258],\n",
      "       device='cuda:0')\n",
      "EPOCH44\n",
      "batch 100 loss:0.056320012286305426\n",
      "batch 200 loss:0.05717042945325375\n",
      "batch 300 loss:0.056410202756524086\n",
      "batch 400 loss:0.056483171209692956\n",
      "batch 500 loss:0.05646369736641645\n",
      "batch 600 loss:0.05593248091638088\n",
      "batch 700 loss:0.05695702064782381\n",
      "LOSS train 0.05695702064782381 valid 0.05644891783595085\n",
      "nmse: [0.13722065 0.465401   0.22801314 ... 0.1255543  0.15296751 0.11378393]\n",
      "mae: tensor([0.1392, 0.1339, 0.1657, 0.1330, 0.2580, 0.2098, 0.3873, 0.2221, 0.2169,\n",
      "        0.2026, 0.2884, 0.1787, 0.2238, 0.2153, 0.1405, 0.1264],\n",
      "       device='cuda:0')\n",
      "EPOCH45\n",
      "batch 100 loss:0.05632277488708496\n",
      "batch 200 loss:0.05719821084290743\n",
      "batch 300 loss:0.056444204896688464\n",
      "batch 400 loss:0.05649405423551798\n",
      "batch 500 loss:0.056460865177214145\n",
      "batch 600 loss:0.056000912226736546\n",
      "batch 700 loss:0.056945909187197684\n",
      "LOSS train 0.056945909187197684 valid 0.05637746676802635\n",
      "nmse: [0.13723455 0.47021577 0.23326927 ... 0.12011565 0.15219843 0.11437589]\n",
      "mae: tensor([0.1409, 0.1354, 0.1659, 0.1345, 0.2547, 0.2117, 0.3855, 0.2212, 0.2163,\n",
      "        0.2036, 0.2848, 0.1772, 0.2264, 0.2098, 0.1406, 0.1265],\n",
      "       device='cuda:0')\n",
      "EPOCH46\n",
      "batch 100 loss:0.05631228093057871\n",
      "batch 200 loss:0.057159213721752165\n",
      "batch 300 loss:0.05643647909164429\n",
      "batch 400 loss:0.0565014123544097\n",
      "batch 500 loss:0.05648217640817165\n",
      "batch 600 loss:0.05594758234918117\n",
      "batch 700 loss:0.05692994635552168\n",
      "LOSS train 0.05692994635552168 valid 0.05641438812017441\n",
      "nmse: [0.1360147  0.46977276 0.23155878 ... 0.12273138 0.14920451 0.11393999]\n",
      "mae: tensor([0.1392, 0.1363, 0.1675, 0.1356, 0.2551, 0.2122, 0.3847, 0.2195, 0.2167,\n",
      "        0.2005, 0.2868, 0.1763, 0.2248, 0.2124, 0.1389, 0.1265],\n",
      "       device='cuda:0')\n",
      "EPOCH47\n",
      "batch 100 loss:0.05632713999599218\n",
      "batch 200 loss:0.05720338560640812\n",
      "batch 300 loss:0.05641708850860596\n",
      "batch 400 loss:0.05649437967687845\n",
      "batch 500 loss:0.0564631899446249\n",
      "batch 600 loss:0.05599845726042986\n",
      "batch 700 loss:0.05698005296289921\n",
      "LOSS train 0.05698005296289921 valid 0.05631700158119202\n",
      "nmse: [0.1353319  0.46485275 0.22535805 ... 0.12129258 0.15463363 0.11656746]\n",
      "mae: tensor([0.1400, 0.1358, 0.1658, 0.1335, 0.2559, 0.2126, 0.3837, 0.2196, 0.2157,\n",
      "        0.2056, 0.2875, 0.1785, 0.2220, 0.2111, 0.1419, 0.1284],\n",
      "       device='cuda:0')\n",
      "EPOCH48\n",
      "batch 100 loss:0.0562937331572175\n",
      "batch 200 loss:0.05716832913458347\n",
      "batch 300 loss:0.056449217908084395\n",
      "batch 400 loss:0.056489281505346295\n",
      "batch 500 loss:0.05646296497434378\n",
      "batch 600 loss:0.05596269585192203\n",
      "batch 700 loss:0.057010548375546935\n",
      "LOSS train 0.057010548375546935 valid 0.0563679002225399\n",
      "nmse: [0.13481034 0.47082877 0.23195225 ... 0.12304031 0.149356   0.11336033]\n",
      "mae: tensor([0.1395, 0.1343, 0.1673, 0.1330, 0.2584, 0.2117, 0.3849, 0.2203, 0.2165,\n",
      "        0.2019, 0.2870, 0.1772, 0.2236, 0.2126, 0.1396, 0.1257],\n",
      "       device='cuda:0')\n",
      "EPOCH49\n",
      "batch 100 loss:0.056293007992208\n",
      "batch 200 loss:0.057220191061496735\n",
      "batch 300 loss:0.05645930223166942\n",
      "batch 400 loss:0.056491402573883534\n",
      "batch 500 loss:0.056459685526788234\n",
      "batch 600 loss:0.05592076741158962\n",
      "batch 700 loss:0.05695703316479921\n",
      "LOSS train 0.05695703316479921 valid 0.056334756314754486\n",
      "nmse: [0.1360531  0.46753377 0.22803253 ... 0.12176559 0.15021217 0.11374424]\n",
      "mae: tensor([0.1388, 0.1383, 0.1676, 0.1344, 0.2570, 0.2121, 0.3858, 0.2202, 0.2151,\n",
      "        0.2047, 0.2869, 0.1776, 0.2255, 0.2116, 0.1398, 0.1255],\n",
      "       device='cuda:0')\n",
      "EPOCH50\n",
      "batch 100 loss:0.05636021822690964\n",
      "batch 200 loss:0.05720504678785801\n",
      "batch 300 loss:0.05645333260297775\n",
      "batch 400 loss:0.05649761285632849\n",
      "batch 500 loss:0.05646339550614357\n",
      "batch 600 loss:0.05595513135194778\n",
      "batch 700 loss:0.056973560526967046\n",
      "LOSS train 0.056973560526967046 valid 0.056352950632572174\n",
      "nmse: [0.13456717 0.4709047  0.23101695 ... 0.12211931 0.15276179 0.11039798]\n",
      "mae: tensor([0.1404, 0.1332, 0.1672, 0.1330, 0.2567, 0.2137, 0.3853, 0.2221, 0.2157,\n",
      "        0.2015, 0.2880, 0.1775, 0.2258, 0.2119, 0.1413, 0.1237],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH{}'.format(epoch_number + 1))\n",
    "\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "    running_vloss = 0.0\n",
    "    \n",
    "    total_nmse = torch.Tensor().to(device)  # Use PyTorch tensor for efficiency\n",
    "    total_mae = torch.Tensor().to(device)\n",
    "    total_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (vdata, _) in enumerate(validation_loader):\n",
    "            vinputs = vdata.view(vdata.shape[0], -1).to(device)\n",
    "            vlabels = validation_labels[i]\n",
    "            voutputs = model(vinputs)\n",
    "            nmse = compute_nmse(voutputs, vlabels)\n",
    "            mae = compute_mae(voutputs, vlabels)\n",
    "            total_nmse = torch.cat((total_nmse, nmse.unsqueeze(0)), dim=1)  # Efficiently concatenate tensors\n",
    "            total_mae = torch.cat((total_mae, mae.unsqueeze(0)), dim=1)\n",
    "            total_samples += vdata.size(0)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "            \n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "    total_nmse = total_nmse.flatten().cpu().numpy()\n",
    "    total_mae = total_mae.flatten().cpu().numpy()\n",
    "    print('nmse: {}'.format(total_nmse))\n",
    "    print('mae: {}'.format(mae))\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                       {'Training' : avg_loss, 'Validation' : avg_vloss},\n",
    "                      epoch_number + 1)\n",
    "\n",
    "    writer.flush()\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14b6eadf-4e87-4150-8b00-e5128f6f2917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 设置图形的大小\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 绘制 NMSE 的分布\n",
    "plt.subplot(1, 2, 1)  # 1行2列的第1个\n",
    "plt.hist(total_nmse, bins=200, alpha=0.7, label='NMSE')\n",
    "# plt.yscale('log')  # 如果需要，开启对数尺度\n",
    "plt.xlabel('NMSE Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of NMSE')\n",
    "plt.xlim(0, 1)  # 根据实际数据范围设置\n",
    "plt.legend()\n",
    "\n",
    "# 绘制 MAE 的分布\n",
    "plt.subplot(1, 2, 2)  # 1行2列的第2个\n",
    "plt.hist(total_mae, bins=50, alpha=0.7, color='red', label='MAE')\n",
    "plt.xlabel('MAE Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of MAE')\n",
    "plt.xlim(0, 2)  # 根据实际数据范围设置\n",
    "plt.legend()\n",
    "\n",
    "# 显示整个图表\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
